{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import torch\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook = sy.TorchHook(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = sy.VirtualWorker(hook, id='bob')\n",
    "alice = sy.VirtualWorker(hook, id='alice')\n",
    "central_server = sy.VirtualWorker(hook, id='central_server')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:root:Worker central_server already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:root:Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:root:Worker central_server already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:root:Worker alice already exists. Replacing old worker which could cause                     unexpected behavior\n",
      "WARNING:root:Worker bob already exists. Replacing old worker which could cause                     unexpected behavior\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<VirtualWorker id:central_server #tensors:0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob.add_workers([alice, central_server])\n",
    "alice.add_workers([bob, central_server])\n",
    "central_server.add_workers([alice, bob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = torch.tensor([[0., 0], [0, 1], [1, 0], [1, 1]], requires_grad=True)\n",
    "target = torch.tensor([[0.],[1], [1], [1]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bob = raw_data[0:2].send(bob)\n",
    "target_bob = target[0:2].send(bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{27214138956: tensor([[0., 0.],\n",
       "         [0., 1.]], requires_grad=True), 61579309777: tensor([[0.],\n",
       "         [1.]], requires_grad=True)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "central_server._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_alice = raw_data[2:].send(alice)\n",
    "target_alice = target[2:].send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{85241161753: tensor([[1., 0.],\n",
       "         [1., 1.]], requires_grad=True), 29055826749: tensor([[1.],\n",
       "         [1.]], requires_grad=True), 24208730054: Parameter containing:\n",
       " tensor([[0.0905, 0.6762]], requires_grad=True), 41820619397: Parameter containing:\n",
       " tensor([0.4906], requires_grad=True)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice._objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'central_server'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "central_server.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=1, bias=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Linear(2, 1)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [(data_bob, target_bob), (data_alice, target_alice)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=1, bias=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_model = model.copy().send(bob)\n",
    "alice_model = model.copy().send(alice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.001\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_optimizer = optim.SGD(bob_model.parameters(), lr=0.001)\n",
    "alice_optimizer = optim.SGD(alice_model.parameters(), lr=0.001)\n",
    "bob_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob_criterion = nn.MSELoss()\n",
    "alice_criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob_pred = bob_model(data_bob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Wrapper)>[PointerTensor | me:12037785948 -> bob:2060883996]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4906],\n",
       "        [1.1669]], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_pred.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'central_server'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "central_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations=20):\n",
    "    \n",
    "    for i in range(iterations):\n",
    "\n",
    "        for _data, _target in dataset:\n",
    "            print(_target.id)\n",
    "\n",
    "#             # Move the model to the various locations\n",
    "#             model = model.send(_data.location)\n",
    "\n",
    "#             # Remove the accumulating Gradients\n",
    "#             optimizer.zero_grad()\n",
    "\n",
    "#             # Make the prediction\n",
    "#             pred = model(_data)\n",
    "\n",
    "#             # Calculate the Loss\n",
    "#             loss = ((pred- _target)**2).sum()\n",
    "\n",
    "#             # Perform the back propagations\n",
    "#             loss.backward()\n",
    "\n",
    "#             # Update the weights\n",
    "#             optimizer.step()\n",
    "\n",
    "#             # Get Smarter model back\n",
    "#             model = model.get()\n",
    "#             print(loss.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n",
      "98159025515\n",
      "16281226221\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
